{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Librerias"
      ],
      "metadata": {
        "id": "gQY8X2dsn1yD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jGl7F5_llc3k"
      },
      "outputs": [],
      "source": [
        "# Instalacion de librerÃ­as para web scraping y manipulaciÃ³n de datos\n",
        "!pip install pandas selenium webdriver-manager\n",
        "!pip install app-store-scraper # Para reseÃ±as de la App Store de Apple\n",
        "!pip install google-play-scraper # Para reseÃ±as de Google Play\n",
        "\n",
        "# Instalacion de librerÃ­as para anÃ¡lisis de sentimiento y NLP\n",
        "!pip install sentiment-analysis-spanish\n",
        "!pip install matplotlib seaborn wordcloud\n",
        "!pip install emoji\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y urllib3 requests six transformers torch\n",
        "!pip install requests==2.32.3 urllib3==2.2.3 six==1.16.0 --quiet\n",
        "!pip install torch==2.8.0 transformers==4.46.2 tqdm --quiet\n"
      ],
      "metadata": {
        "id": "sgiR6LMLxFQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "os.kill(os.getpid(), 9)\n"
      ],
      "metadata": {
        "id": "Ew2zq0yM64B-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fase 1: RecolecciÃ³n de Datos (Web Scraping)"
      ],
      "metadata": {
        "id": "L2pToNGbn61R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Importar las librerÃ­as necesarias\n",
        "import pandas as pd\n",
        "from google_play_scraper import reviews\n",
        "from google_play_scraper import Sort\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "# --- CONFIGURACIÃ“N ---\n",
        "nombre_archivo_excel = 'ListaApps.xlsx'      # Nombre del archivo Excel\n",
        "nombre_columna_url = 'url_google_play'        # Columna con las URLs de las apps\n",
        "nombre_columna_app = 'nombre_de_la_app'       # Columna con los nombres de las apps\n",
        "limite_reseÃ±as = 5000                         # NÃºmero mÃ¡ximo de reseÃ±as a descargar\n",
        "# --------------------\n",
        "\n",
        "\n",
        "# 2. Cargar tu archivo de Excel en un DataFrame de pandas\n",
        "try:\n",
        "    df_apps = pd.read_excel(nombre_archivo_excel)\n",
        "    print(\"âœ… Â¡Excel cargado correctamente!\")\n",
        "    print(df_apps.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"âŒ Error: No se encontrÃ³ el archivo '{nombre_archivo_excel}'.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# 3. FunciÃ³n para extraer el ID de la aplicaciÃ³n desde la URL\n",
        "def extraer_id_de_url(url):\n",
        "    \"\"\"Extrae el ID de una app desde su URL de Google Play.\"\"\"\n",
        "    if not isinstance(url, str):\n",
        "        return None\n",
        "    try:\n",
        "        parsed_url = urlparse(url)\n",
        "        query_params = parse_qs(parsed_url.query)\n",
        "        return query_params['id'][0]\n",
        "    except (KeyError, IndexError):\n",
        "        print(f\"âš ï¸ Advertencia: No se pudo extraer el ID de la URL: {url}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# 4. Crear columna con los IDs\n",
        "df_apps['app_id'] = df_apps[nombre_columna_url].apply(extraer_id_de_url)\n",
        "df_apps.dropna(subset=['app_id'], inplace=True)\n",
        "\n",
        "print(\"\\nðŸ“± DataFrame con IDs extraÃ­dos:\")\n",
        "print(df_apps.head())\n",
        "\n",
        "\n",
        "# 5. Descargar las reseÃ±as mÃ¡s recientes de cada app\n",
        "print(\"\\n--- Iniciando la descarga de reseÃ±as ---\")\n",
        "\n",
        "for index, fila in df_apps.iterrows():\n",
        "    app_nombre = fila[nombre_columna_app]\n",
        "    app_id = fila['app_id']\n",
        "\n",
        "    print(f\"\\nDescargando reseÃ±as mÃ¡s recientes para: {app_nombre} (ID: {app_id})\")\n",
        "\n",
        "    try:\n",
        "        # Usamos 'reviews' en lugar de 'reviews_all'\n",
        "        resultado, _ = reviews(\n",
        "            app_id,\n",
        "            lang='es',               # Idioma espaÃ±ol\n",
        "            country='co',            # PaÃ­s Colombia\n",
        "            sort=Sort.NEWEST,        # Ordenar por las mÃ¡s recientes\n",
        "            count=limite_reseÃ±as     # Limitar a 5000 reseÃ±as\n",
        "        )\n",
        "\n",
        "        # Convertir a DataFrame\n",
        "        df_reviews = pd.DataFrame(resultado)\n",
        "\n",
        "        # Guardar en CSV\n",
        "        nombre_archivo_csv = f'reseÃ±as_{app_nombre.replace(\" \", \"_\")}.csv'\n",
        "        df_reviews.to_csv(nombre_archivo_csv, index=False)\n",
        "        print(f\"âœ… Se guardaron {len(df_reviews)} reseÃ±as en '{nombre_archivo_csv}'\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error al descargar reseÃ±as de {app_nombre}: {e}\")\n",
        "\n",
        "print(\"\\n--- Proceso de descarga finalizado ---\")\n"
      ],
      "metadata": {
        "id": "G8CdxhFquAIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fase 2: UnificaciÃ³n de reseÃ±as y eliminaciÃ³n de columnas innecesarias"
      ],
      "metadata": {
        "id": "gV1oRsS83Anf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob # LibrerÃ­a para buscar archivos por patrÃ³n\n",
        "\n",
        "print(\"--- Iniciando la unificaciÃ³n de archivos CSV ---\")\n",
        "\n",
        "# 1. Definir el patrÃ³n de bÃºsqueda\n",
        "patron_archivos = 'reseÃ±as_*.csv'\n",
        "\n",
        "# 2. Usar 'glob' para encontrar todos los archivos que coincidan\n",
        "archivos_csv_encontrados = glob.glob(patron_archivos)\n",
        "\n",
        "if not archivos_csv_encontrados:\n",
        "    print(f\"âŒ Error: No se encontrÃ³ ningÃºn archivo con el patrÃ³n '{patron_archivos}'.\")\n",
        "    print(\"AsegÃºrate de que el primer script se haya ejecutado y generado los archivos.\")\n",
        "else:\n",
        "    print(f\"âœ… Se encontraron {len(archivos_csv_encontrados)} archivos para unificar.\")\n",
        "\n",
        "    # 3. Leer cada archivo CSV y guardarlo en una lista de DataFrames\n",
        "    lista_de_dataframes = []\n",
        "    for archivo in archivos_csv_encontrados:\n",
        "        try:\n",
        "            df_temp = pd.read_csv(archivo)\n",
        "\n",
        "            # Creamos la columna con el nombre de la app a partir del nombre del archivo\n",
        "            # Como el formato es 'reseÃ±as_Nombre_De_La_App.csv'\n",
        "\n",
        "            # 1. Quitamos el prefijo 'reseÃ±as_' y el sufijo '.csv'\n",
        "            nombre_base = archivo[len('reseÃ±as_'):-len('.csv')]\n",
        "\n",
        "            # 2. Revertimos los '_' a espacios\n",
        "            nombre_app_limpio = nombre_base.replace(\"_\", \" \")\n",
        "\n",
        "            # 3. Creamos la nueva columna\n",
        "            df_temp['nombre_app'] = nombre_app_limpio\n",
        "            # ------------------------\n",
        "\n",
        "            lista_de_dataframes.append(df_temp)\n",
        "            print(f\"  ...cargando {archivo} ({len(df_temp)} filas) -> App: {nombre_app_limpio}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Advertencia: No se pudo leer el archivo '{archivo}'. Error: {e}\")\n",
        "\n",
        "    # 4. Combinar (concatenar) todos los DataFrames de la lista en uno solo\n",
        "    if lista_de_dataframes:\n",
        "        # pd.concat une todos los dataframes\n",
        "        # ignore_index=True crea un Ã­ndice nuevo y limpio para el dataframe final\n",
        "        df = pd.concat(lista_de_dataframes, ignore_index=True)\n",
        "\n",
        "        print(f\"\\n Â¡UnificaciÃ³n completa! El DataFrame 'df' tiene {len(df)} filas en total.\")\n",
        "\n",
        "        # 5. Guardar el DataFrame unificado en un archivo Excel\n",
        "        nombre_excel_final = 'final_google_store.xlsx'\n",
        "        try:\n",
        "            # Usamos index=False para no guardar el Ã­ndice de pandas en el Excel\n",
        "            df.to_excel(nombre_excel_final, index=False)\n",
        "            print(f\"âœ… DataFrame unificado guardado exitosamente en '{nombre_excel_final}'\")\n",
        "\n",
        "            # 6. Mostrar un vistazo del DataFrame final (variable 'df')\n",
        "            print(\"\\n--- Primeras 5 filas del DataFrame 'df' unificado (con la nueva columna) ---\")\n",
        "            print(df.head())\n",
        "\n",
        "            # Mostrar tambiÃ©n las columnas para verificar 'nombre_app'\n",
        "            print(\"\\nColumnas del DataFrame final:\")\n",
        "            print(df.columns)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error al guardar el archivo Excel: {e}\")\n",
        "            print(\"Verifica si tienes los permisos necesarios o si el archivo ya estÃ¡ abierto.\")\n",
        "    else:\n",
        "        print(\"âŒ Error: No se pudo cargar ningÃºn DataFrame para unificar.\")"
      ],
      "metadata": {
        "id": "oKaKgJfT2tkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Se borran las columnas que no se usarÃ¡n\n",
        "\n",
        "columnas_a_borrar = [\n",
        "    'userName',\n",
        "    'reviewId',\n",
        "    'userImage',\n",
        "    'thumbsUpCount',\n",
        "    'reviewCreatedVersion',\n",
        "    'replyContent',\n",
        "    'repliedAt',\n",
        "    'appVersion'\n",
        "]\n",
        "\n",
        "df = df.drop(columns=columnas_a_borrar, errors='ignore')\n"
      ],
      "metadata": {
        "id": "EYJ2eTEg4nhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "QvmUzmz09Fzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aplicamos formato a la columna 'at' (fecha de la reseÃ±a)\n",
        "\n",
        "# 1. Asegurarse de que la columna 'at' sea del tipo datetime\n",
        "df['at'] = pd.to_datetime(df['at'])\n",
        "\n",
        "# 2. Normalizar la fecha (eliminar la hora)\n",
        "#    .dt.normalize() establece la hora, minutos y segundos a cero.\n",
        "#    Crearemos una nueva columna para mantener el dato original para backup.\n",
        "df['fecha'] = df['at'].dt.normalize()\n",
        "\n",
        "# 3. (Opcional) Si se quiere la fecha como un string en formato D/M/A\n",
        "#     Ãºtil solo para visualizaciÃ³n final, no para cÃ¡lculos.\n",
        "# df['fecha_texto'] = df['at'].dt.strftime('%d/%m/%Y')\n",
        "\n",
        "# --- VerificaciÃ³n ---\n",
        "print(\"ComparaciÃ³n de la columna original 'at' y la nueva 'fecha':\")\n",
        "print(df[['at', 'fecha']].head())\n",
        "\n"
      ],
      "metadata": {
        "id": "Qcfx8j0x6vsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fase 3: Limpieza y Preprocesamiento de Datos"
      ],
      "metadata": {
        "id": "1mSFuN6-Np7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "import emoji\n",
        "import chardet\n",
        "\n",
        "\n",
        "# 1 print(df.head())\n",
        "\n",
        "# 2ï¸ FunciÃ³n para corregir errores de codificaciÃ³n\n",
        "def corregir_codificacion(texto):\n",
        "    \"\"\"Corrige problemas de codificaciÃ³n comunes (UTF-8 mal interpretado como latin-1).\"\"\"\n",
        "    if not isinstance(texto, str):\n",
        "        return texto\n",
        "\n",
        "    # 1. Intentar corregir maldecodificaciÃ³n tÃ­pica (ÃƒÂ³ â†’ Ã³)\n",
        "    try:\n",
        "        texto_corregido = texto.encode('latin1').decode('utf-8')\n",
        "    except:\n",
        "        texto_corregido = texto\n",
        "\n",
        "    # 2. Detectar y corregir codificaciÃ³n restante si es posible\n",
        "    try:\n",
        "        resultado = chardet.detect(texto_corregido.encode())\n",
        "        encoding_detectado = resultado['encoding']\n",
        "        if encoding_detectado and encoding_detectado.lower() != 'utf-8':\n",
        "            texto_corregido = texto_corregido.encode(encoding_detectado).decode('utf-8', errors='ignore')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # 3. Reemplazos manuales de patrones frecuentes\n",
        "    reemplazos = {\n",
        "        'ÃƒÂ¡': 'Ã¡', 'ÃƒÂ©': 'Ã©', 'ÃƒÂ­': 'Ã­', 'ÃƒÂ³': 'Ã³', 'ÃƒÂº': 'Ãº',\n",
        "        'ÃƒÂ±': 'Ã±', 'ÃƒÂ': 'Ã', 'Ãƒâ€°': 'Ã‰', 'ÃƒÂ': 'Ã', 'Ãƒâ€œ': 'Ã“', 'ÃƒÅ¡': 'Ãš', 'Ãƒâ€˜': 'Ã‘',\n",
        "        'Ã¢â‚¬Â': '', 'Ã¢â‚¬â„¢': \"'\", 'Ã¢â‚¬Å“': '\"', 'Ã¢â‚¬': '\"', 'Ã¢â‚¬â€œ': '-', 'Ã¢â‚¬Â¢': 'â€¢',\n",
        "        'Ã¢â‚¬Ëœ': \"'\", 'Ã¢â‚¬Â¢': '', 'Ã¢â‚¬â€': '-', 'Ã‚': ''\n",
        "    }\n",
        "    for k, v in reemplazos.items():\n",
        "        texto_corregido = texto_corregido.replace(k, v)\n",
        "\n",
        "    return texto_corregido\n",
        "\n",
        "\n",
        "# 3ï¸ FunciÃ³n de limpieza completa\n",
        "def limpiar_texto(texto):\n",
        "    if not isinstance(texto, str):\n",
        "        return \"\"\n",
        "\n",
        "    # --- CorrecciÃ³n de codificaciÃ³n ---\n",
        "    texto = corregir_codificacion(texto)\n",
        "\n",
        "    # --- NormalizaciÃ³n ---\n",
        "    texto = texto.lower()\n",
        "\n",
        "    # --- EliminaciÃ³n de ruido ---\n",
        "    texto = re.sub(r'http\\S+|www\\S+', '', texto)     # eliminar links\n",
        "    texto = re.sub(r'@\\w+', '', texto)               # eliminar menciones\n",
        "    texto = re.sub(r'#\\w+', '', texto)               # eliminar hashtags\n",
        "    texto = emoji.replace_emoji(texto, replace='')   # eliminar emojis\n",
        "\n",
        "    # --- Mantener solo letras y acentos en espaÃ±ol ---\n",
        "    texto = re.sub(r'[^a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼\\s]', '', texto)\n",
        "\n",
        "    # --- Espacios extra ---\n",
        "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
        "\n",
        "    return texto\n",
        "\n",
        "\n",
        "# 4ï¸ Aplicar limpieza sobre la columna 'content'\n",
        "df['texto_limpio'] = df['content'].apply(limpiar_texto)\n",
        "\n",
        "\n",
        "# 5ï¸ Vista previa del resultado\n",
        "print(\"\\n Vista previa del texto limpio:\")\n",
        "print(df[['content', 'texto_limpio']].head(10))\n",
        "\n",
        "\n",
        "# 6ï¸ Guardar dataset limpio\n",
        "nombre_salida = \"reseÃ±as_limpias.csv\"\n",
        "df.to_csv(nombre_salida, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(f\"\\n Archivo '{nombre_salida}' guardado correctamente.\")\n",
        "print(f\"Total de reseÃ±as procesadas: {len(df)}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qVFYHOzItSH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#eliminamos las filas donde el campo 'texto_limpio' estÃ¡ vaciÃ³\n",
        "\n",
        "print(\"--- Eliminando filas con 'texto_limpio' vacÃ­o ---\")\n",
        "\n",
        "# Guardar el nÃºmero de filas antes de la limpieza\n",
        "filas_antes = len(df)\n",
        "\n",
        "# 1. Reemplazar cadenas vacÃ­as o que solo contienen espacios con 'pd.NA'\n",
        "# ^ -> inicio de la cadena\n",
        "# \\s* -> cero o mÃ¡s caracteres de espacio en blanco (espacios, tabs, etc.)\n",
        "# $ -> fin de la cadena\n",
        "df['texto_limpio'] = df['texto_limpio'].replace(r'^\\s*$', pd.NA, regex=True)\n",
        "\n",
        "# 2. Eliminar todas las filas donde 'texto_limpio' sea ahora nulo (pd.NA o NaN)\n",
        "# Usamos re-asignaciÃ³n (df = ...) en lugar de inplace=True\n",
        "df = df.dropna(subset=['texto_limpio'])\n",
        "\n",
        "# 3. Informar el resultado\n",
        "filas_despues = len(df)\n",
        "print(f\" Se eliminaron {filas_antes - filas_despues} filas.\")\n",
        "print(f\"El DataFrame 'df' ahora tiene {filas_despues} filas.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "VQuiq-w9AC8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "X2WzmeNlBwWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fase 4: anÃ¡lisis de sentimientos con sentiment_spanish"
      ],
      "metadata": {
        "id": "yHShmjNhB_Aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentiment_analysis_spanish import sentiment_analysis\n",
        "\n",
        "# Inicializar el analizador\n",
        "analizador = sentiment_analysis.SentimentAnalysisSpanish()\n",
        "\n",
        "def analizar_sentimiento(texto):\n",
        "    if not texto.strip(): # Si el texto estÃ¡ vacÃ­o\n",
        "        return 0.5 # Neutral por defecto\n",
        "    return analizador.sentiment(texto)\n",
        "\n",
        "# Aplicar el anÃ¡lisis a la columna de texto limpio\n",
        "# El resultado es un valor entre 0 (negativo) y 1 (positivo)\n",
        "df['sentimiento_score_spa'] = df['texto_limpio'].apply(analizar_sentimiento)\n",
        "\n",
        "# Clasificar el sentimiento\n",
        "def clasificar_sentimiento(score):\n",
        "    if score > 0.6:\n",
        "        return 'Positivo'\n",
        "    elif score < 0.4:\n",
        "        return 'Negativo'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "df['sentimiento_spa'] = df['sentimiento_score_spa'].apply(clasificar_sentimiento)\n",
        "print(df[['texto_limpio', 'sentimiento_spa']].head())"
      ],
      "metadata": {
        "id": "E8vPwib1vSiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "7XkCz7HrwRNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fase 5: evaluar resultados"
      ],
      "metadata": {
        "id": "nmGz-NXzDxvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Por defecto el usuario en la reseÃ±a puede dar una calificaciÃ³n Â´scoreÂ´ de 4 a 5 - vamos a comparar con los resultados de 'sentimiento_spa':\n",
        "\n",
        "# Filtrar solo reseÃ±as con score 4 o 5\n",
        "altas = df[df['score'].isin([4, 5])]\n",
        "\n",
        "# Contar cuÃ¡ntas de esas fueron clasificadas como \"Negativo\"\n",
        "negativas_en_altas = altas[altas['sentimiento_spa'] == 'Negativo']\n",
        "\n",
        "# Calcular la proporciÃ³n\n",
        "proporcion = len(negativas_en_altas) / len(altas) if len(altas) > 0 else 0\n",
        "\n",
        "print(f\"ProporciÃ³n de reseÃ±as con score 4 o 5 clasificadas como 'Negativas': {proporcion:.2%}\")\n"
      ],
      "metadata": {
        "id": "HhqAjtV4y7S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar solo reseÃ±as con score de 1 - 2\n",
        "bajas = df[df['score'].isin([1,2])]\n",
        "\n",
        "# Contar cuÃ¡ntas de esas fueron clasificadas como \"Positivos\"\n",
        "positivas_en_bajas = bajas[bajas['sentimiento_spa'] == 'Positivo']\n",
        "\n",
        "# Calcular la proporciÃ³n\n",
        "proporcion = len(positivas_en_bajas) / len(bajas) if len(bajas) > 0 else 0\n",
        "\n",
        "print(f\"ProporciÃ³n de reseÃ±as con score 1 - 2 clasificadas como 'Postivas': {proporcion:.2%}\")\n"
      ],
      "metadata": {
        "id": "FYGk8eBJzCOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#eliminar la columna: 'sentimiento_score_spa'\n",
        "\n",
        "df = df.drop(columns=['sentimiento_score_spa'])\n",
        "#df.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EA4ubCbu04-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fase 6: AnÃ¡lisis de sentimientos con transformers"
      ],
      "metadata": {
        "id": "G3kJ4l38FaHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Inicializar el analizador de sentimientos\n",
        "analizador_transformer = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        ")\n",
        "\n",
        "# FunciÃ³n de anÃ¡lisis\n",
        "def analizar_sentimiento_transformer(texto):\n",
        "    if not isinstance(texto, str) or not texto.strip():\n",
        "        return \"Neutral\"\n",
        "    try:\n",
        "        resultado = analizador_transformer(texto[:512])[0]\n",
        "        label = resultado['label']\n",
        "        if label in ['1 star', '2 stars']:\n",
        "            return 'Negativo'\n",
        "        elif label == '3 stars':\n",
        "            return 'Neutral'\n",
        "        else:\n",
        "            return 'Positivo'\n",
        "    except Exception as e:\n",
        "        print(f\"Error analizando texto: {e}\")\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Aplicar al DataFrame df\n",
        "tqdm.pandas()\n",
        "df['sentimiento_transformer'] = df['texto_limpio'].progress_apply(analizar_sentimiento_transformer)\n",
        "\n",
        "df[['texto_limpio', 'score', 'sentimiento_transformer']].head()\n"
      ],
      "metadata": {
        "id": "xW9Fu55W68Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "P-dqabuheK3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exportar el DataFrame a un archivo Excel\n",
        "df.to_excel(\"sentimientos_transformer.xlsx\", index=False)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"sentimientos_transformer.xlsx\")"
      ],
      "metadata": {
        "id": "LLingmo7HRSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fase 7: Evaluar resultados"
      ],
      "metadata": {
        "id": "eliEe0HbKf-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar solo reseÃ±as con score 4 o 5\n",
        "altas = df[df['score'].isin([4, 5])]\n",
        "\n",
        "# Contar cuÃ¡ntas de esas fueron clasificadas como \"Negativo\"\n",
        "negativas_en_altas = altas[altas['sentimiento_transformer'] == 'Negativo']\n",
        "\n",
        "# Calcular la proporciÃ³n\n",
        "proporcion = len(negativas_en_altas) / len(altas) if len(altas) > 0 else 0\n",
        "\n",
        "print(f\"ProporciÃ³n de reseÃ±as con score 4 o 5 clasificadas como 'Negativas': {proporcion:.2%}\")"
      ],
      "metadata": {
        "id": "xclM1QdjeRUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar solo reseÃ±as con score de 1 a 2\n",
        "bajas = df[df['score'].isin([1,2])]\n",
        "\n",
        "# Contar cuÃ¡ntas de esas fueron clasificadas como \"Positivos\"\n",
        "positivas_en_bajas = bajas[bajas['sentimiento_transformer'] == 'Positivo']\n",
        "\n",
        "# Calcular la proporciÃ³n\n",
        "proporcion = len(positivas_en_bajas) / len(bajas) if len(bajas) > 0 else 0\n",
        "\n",
        "print(f\"ProporciÃ³n de reseÃ±as con score 1 a 3 clasificadas como 'Positivas': {proporcion:.2%}\")"
      ],
      "metadata": {
        "id": "Bx4fOlm0etQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "o23zgKIVfZbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fase 8: Medir el nivel de concordancia entre el sentimiento predicho (spanish y transformers) y el score del usuario"
      ],
      "metadata": {
        "id": "36PJH9QLhu-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simplificar el score\n",
        "df['score_label'] = df['score'].apply(lambda x: 'Positivo' if x >= 4 else ('Negativo' if x <= 2 else 'Neutral'))\n",
        "\n",
        "# Comparar con el sentimiento de cada modelo\n",
        "concordancia_spanish = (df['score_label'] == df['sentimiento_spa']).mean()\n",
        "concordancia_transformer = (df['score_label'] == df['sentimiento_transformer']).mean()\n",
        "\n",
        "print(f\"Concordancia SentimentAnalysisSpanish: {concordancia_spanish:.2%}\")\n",
        "print(f\"Concordancia Transformer: {concordancia_transformer:.2%}\")\n"
      ],
      "metadata": {
        "id": "75_x7Eechhrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fase 9: GrÃ¡fico de falsos negativos y falsos positivos (para comparar errores entre los dos modelos)"
      ],
      "metadata": {
        "id": "5a57whFhiit1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1ï¸ Crear etiqueta de sentimiento segÃºn el score del usuario\n",
        "df['score_label'] = df['score'].apply(\n",
        "    lambda x: 'Positivo' if x >= 4 else ('Negativo' if x <= 2 else 'Neutral')\n",
        ")\n",
        "\n",
        "# 2ï¸ Calcular la concordancia entre el sentimiento y el score\n",
        "concordancia_spanish = (df['score_label'] == df['sentimiento_spa']).mean()\n",
        "concordancia_transformer = (df['score_label'] == df['sentimiento_transformer']).mean()\n",
        "\n",
        "# 3ï¸ Resumen con proporciones\n",
        "datos = {\n",
        "    'Modelo': ['SentimentAnalysisSpanish', 'Transformer (BERT)'],\n",
        "    'Negativos con score 4-5 (%)': [28.44, 9.88],\n",
        "    'Positivos con score 1-2 (%)': [1.52, 3.38],\n",
        "    'Concordancia (%)': [concordancia_spanish * 100, concordancia_transformer * 100]\n",
        "}\n",
        "\n",
        "tabla_comparativa = pd.DataFrame(datos)\n",
        "\n",
        "# === GRÃFICA 1: Concordancia general ===\n",
        "plt.figure(figsize=(8, 5))\n",
        "bars = plt.bar(tabla_comparativa['Modelo'], tabla_comparativa['Concordancia (%)'], color=['#4c72b0', '#55a868'])\n",
        "plt.title('Concordancia entre el score del usuario y el sentimiento detectado', fontsize=13)\n",
        "plt.ylabel('Concordancia (%)')\n",
        "plt.ylim(0, 100)\n",
        "\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 1, f'{yval:.2f}%', ha='center', fontsize=11)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# === GRÃFICA 2: Falsos negativos y positivos ===\n",
        "ancho_barra = 0.35\n",
        "x = np.arange(len(tabla_comparativa['Modelo']))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "b1 = ax.bar(x - ancho_barra/2, tabla_comparativa['Negativos con score 4-5 (%)'], ancho_barra, label='Falsos Negativos', color='#d62728')\n",
        "b2 = ax.bar(x + ancho_barra/2, tabla_comparativa['Positivos con score 1-2 (%)'], ancho_barra, label='Falsos Positivos', color='#1f77b4')\n",
        "\n",
        "ax.set_ylabel('ProporciÃ³n (%)')\n",
        "ax.set_title('ComparaciÃ³n de errores de clasificaciÃ³n entre modelos')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(tabla_comparativa['Modelo'], rotation=10)\n",
        "ax.legend()\n",
        "\n",
        "for b in b1 + b2:\n",
        "    yval = b.get_height()\n",
        "    ax.text(b.get_x() + b.get_width()/2, yval + 0.5, f'{yval:.2f}%', ha='center', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# === Mostrar tabla resumen ===\n",
        "print(\"\\nðŸ“Š Comparativo general de desempeÃ±o entre modelos:\")\n",
        "display(tabla_comparativa)\n"
      ],
      "metadata": {
        "id": "rF1GLFZsie7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# --- PreparaciÃ³n ---\n",
        "# 1. Definir el orden de las etiquetas\n",
        "# Para que la matriz (Pos, Neg, Neu) se muestre en un orden lÃ³gico\n",
        "# y sea igual para ambos modelos, permitiendo una comparaciÃ³n justa.\n",
        "labels_order = ['Positivo', 'Negativo', 'Neutral']\n",
        "\n",
        "# 2. Extraer los datos (Realidad vs. PredicciÃ³n)\n",
        "y_real = df['score_label']\n",
        "y_pred_spa = df['sentimiento_spa']\n",
        "y_pred_transformer = df['sentimiento_transformer']\n",
        "\n",
        "\n",
        "# === GRÃFICA 3: Matriz de ConfusiÃ³n - SentimentAnalysisSpanish ===\n",
        "\n",
        "print(\"\\n--- 1. Matriz de ConfusiÃ³n (SentimentAnalysisSpanish) ---\")\n",
        "\n",
        "# 1. Calcular la Matriz de ConfusiÃ³n\n",
        "cm_spa = confusion_matrix(y_real, y_pred_spa, labels=labels_order)\n",
        "\n",
        "# 2. Graficar el Heatmap\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.heatmap(cm_spa,\n",
        "            annot=True,     # Mostrar los nÃºmeros en cada celda\n",
        "            fmt='d',        # Formato de los nÃºmeros (enteros)\n",
        "            cmap='Blues',   # Paleta de colores\n",
        "            xticklabels=labels_order,\n",
        "            yticklabels=labels_order)\n",
        "\n",
        "plt.title('Matriz de ConfusiÃ³n: SentimentAnalysisSpanish')\n",
        "plt.ylabel('Realidad (Score Usuario)')\n",
        "plt.xlabel('PredicciÃ³n del Modelo')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# === GRÃFICA 4: Matriz de ConfusiÃ³n - Transformer (BERT) ===\n",
        "\n",
        "print(\"\\n--- 2. Matriz de ConfusiÃ³n (Transformer - BERT) ---\")\n",
        "\n",
        "# 1. Calcular la Matriz de ConfusiÃ³n\n",
        "cm_transformer = confusion_matrix(y_real, y_pred_transformer, labels=labels_order)\n",
        "\n",
        "# 2. Graficar el Heatmap\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.heatmap(cm_transformer,\n",
        "            annot=True,\n",
        "            fmt='d',\n",
        "            cmap='Oranges', # Usamos otro color para diferenciarlo\n",
        "            xticklabels=labels_order,\n",
        "            yticklabels=labels_order)\n",
        "\n",
        "plt.title('Matriz de ConfusiÃ³n: Transformer (BERT)')\n",
        "plt.ylabel('Realidad (Score Usuario)')\n",
        "plt.xlabel('PredicciÃ³n del Modelo')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# === (Opcional pero recomendado) Reporte de ClasificaciÃ³n ===\n",
        "# Esto te da la PrecisiÃ³n, Recall y F1-Score para cada clase\n",
        "\n",
        "print(\"\\n\\n--- Reporte de ClasificaciÃ³n (SentimentAnalysisSpanish) ---\")\n",
        "print(classification_report(y_real, y_pred_spa, labels=labels_order, digits=3))\n",
        "\n",
        "print(\"\\n--- Reporte de ClasificaciÃ³n (Transformer - BERT) ---\")\n",
        "print(classification_report(y_real, y_pred_transformer, labels=labels_order, digits=3))"
      ],
      "metadata": {
        "id": "ZooZUlSGSpqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fase 10: Resultados y anÃ¡lisis del sentimiento de las aplicaciones financiereas"
      ],
      "metadata": {
        "id": "lKlTbLIJTOFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LTcJl8j_TZkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Generando grÃ¡fico de proporciones de sentimiento ---\")\n",
        "\n",
        "# --- 1. Preparar los datos para ordenar ---\n",
        "# calcular el porcentaje de 'Negativo' para cada app.\n",
        "\n",
        "# 1a. Contar los sentimientos por app\n",
        "df_counts = df.groupby('nombre_app')['sentimiento_transformer'].value_counts()\n",
        "\n",
        "# 1b. Calcular el total de reseÃ±as por app\n",
        "df_total = df.groupby('nombre_app')['sentimiento_transformer'].count()\n",
        "\n",
        "# 1c. Calcular la proporciÃ³n de cada sentimiento\n",
        "df_proportions = (df_counts / df_total).unstack(fill_value=0)\n",
        "\n",
        "# 1d. Obtener el order para el grÃ¡fico:\n",
        "# Ordenamos las apps por 'Negativo' de mayor a menor.\n",
        "if 'Negativo' in df_proportions.columns:\n",
        "    order_apps = df_proportions.sort_values(by='Negativo', ascending=False).index.tolist() # Convert to list\n",
        "else:\n",
        "    print(\"Advertencia: No se encontraron reseÃ±as 'Negativo' para ordenar.\")\n",
        "    order_apps = df_proportions.index.tolist() # Convert to list (Order by default)\n",
        "\n",
        "\n",
        "print(\"Orden de apps (de mÃ¡s negativas a menos):\", order_apps)\n",
        "\n",
        "\n",
        "# --- 2. Configurar el estilo del grÃ¡fico ---\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "\n",
        "# --- 3. Graficar usando pandas plot (Stacked Bar) ---\n",
        "\n",
        "# Reorder the dataframe based on the order_apps list\n",
        "df_proportions_ordered = df_proportions.reindex(order_apps)\n",
        "\n",
        "# Define colors for the sentiments\n",
        "colors = {'Positivo':'#2ca02c', 'Negativo':'#d62728', 'Neutral':'#ff7f0e'}\n",
        "# Ensure columns are in a desired order for stacking (e.g., Negativo, Neutral, Positivo)\n",
        "column_order = ['Negativo', 'Neutral', 'Positivo']\n",
        "# Filter columns to include only those present in df_proportions_ordered\n",
        "columns_to_plot = [col for col in column_order if col in df_proportions_ordered.columns]\n",
        "\n",
        "\n",
        "ax = df_proportions_ordered[columns_to_plot].plot(kind='bar', stacked=True, color=[colors[col] for col in columns_to_plot], ax=plt.gca())\n",
        "\n",
        "\n",
        "# --- 4. Ajustes y limpieza del grÃ¡fico ---\n",
        "ax.set_title('ProporciÃ³n de Sentimientos por App Financiera', fontsize=16, weight='bold')\n",
        "ax.set_ylabel('ProporciÃ³n de ReseÃ±as (100%)')\n",
        "ax.set_xlabel('AplicaciÃ³n')\n",
        "\n",
        "# Ajusta las etiquetas del eje Y para mostrar porcentajes\n",
        "ax.set_yticklabels(['{:,.0%}'.format(y) for y in ax.get_yticks()])\n",
        "\n",
        "# Rota etiquetas del eje X si son muchas apps\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Mover la leyenda fuera del grÃ¡fico\n",
        "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- 5. Mostrar la tabla de proporciones ---\n",
        "print(\"\\n--- Tabla de Proporciones (para referencia) ---\")\n",
        "# Multiplicamos por 100 y redondeamos\n",
        "print(df_proportions.mul(100).round(2).sort_values(by='Negativo', ascending=False))"
      ],
      "metadata": {
        "id": "TRg4C2t3TWwy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}